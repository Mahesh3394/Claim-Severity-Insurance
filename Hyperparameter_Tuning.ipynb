{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Algorithm (Hyperparameter Tuning):"
      ],
      "metadata": {
        "id": "Pc9tWQ8__SYI"
      },
      "id": "Pc9tWQ8__SYI"
    },
    {
      "cell_type": "code",
      "source": [
        "features = [x for x in train.columns if x not in ['id','loss']]\n",
        "\n",
        "cat_features = [x for x in train.select_dtypes(\n",
        "        include=['object']).columns if x not in ['id','loss']]\n",
        "num_features = [x for x in train.select_dtypes(\n",
        "        exclude=['object']).columns if x not in ['id','loss',]]"
      ],
      "metadata": {
        "id": "tFWcC_VHHd2w"
      },
      "id": "tFWcC_VHHd2w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f858f923",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f858f923",
        "outputId": "be922d5b-8d9f-441e-f340-12be285083ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain: (188318, 130)\n",
            "ytrain: (188318,)\n"
          ]
        }
      ],
      "source": [
        "ntrain = train.shape[0]\n",
        "\n",
        "train_x = train[features]\n",
        "train_y = train['loss']\n",
        "#categorized each categorical variables into numerical value by using below code\n",
        "for c in range(len(cat_features)):\n",
        "    train_x[cat_features[c]] = train_x[cat_features[c]].astype('category').cat.codes\n",
        "    \n",
        "print( \"Xtrain:\", train_x.shape)\n",
        "print( \"ytrain:\", train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_cv_base,y_train,y_cv=train_test_split(train_x,train_y,test_size=0.2)"
      ],
      "metadata": {
        "id": "dnR4ewTjm04U"
      },
      "id": "dnR4ewTjm04U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning by using RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "xgb_param_grid = {'gamma':[ 0.1 * i for i in range(0,5)],\n",
        "                 'subsample':[ 0.1 * i for i in range(5,10)],\n",
        "                'colsample_bytree':[ 0.1 * i for i in range(5,10)]}\n",
        "\n",
        "xgb_model = XGBRegressor()\n",
        "XGB_random = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_grid,\n",
        "                                   n_iter=5,cv = 3,scoring='neg_mean_absolute_error',random_state=25,verbose=3,n_jobs=-1)\n",
        "\n",
        "XGB_random.fit(x_train, y_train.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1y2GybWHtab",
        "outputId": "e046ab8d-d1cb-45ec-991b-71b3326bcb35"
      },
      "id": "B1y2GybWHtab",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "[14:18:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=XGBRegressor(), n_iter=5, n_jobs=-1,\n",
              "                   param_distributions={'colsample_bytree': [0.5,\n",
              "                                                             0.6000000000000001,\n",
              "                                                             0.7000000000000001,\n",
              "                                                             0.8, 0.9],\n",
              "                                        'gamma': [0.0, 0.1, 0.2,\n",
              "                                                  0.30000000000000004, 0.4],\n",
              "                                        'subsample': [0.5, 0.6000000000000001,\n",
              "                                                      0.7000000000000001, 0.8,\n",
              "                                                      0.9]},\n",
              "                   random_state=25, scoring='neg_mean_absolute_error',\n",
              "                   verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_random.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdQ5fvRTeHWx",
        "outputId": "6bc66858-8e67-49bb-9064-9f6521e0ff13"
      },
      "id": "ZdQ5fvRTeHWx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([42.1159087 , 37.78492133, 39.81208793, 41.54098248, 32.77899106]),\n",
              " 'mean_score_time': array([0.35750484, 0.3298804 , 0.31528974, 0.30607009, 0.2866923 ]),\n",
              " 'mean_test_score': array([-1255.83230928, -1253.69140322, -1253.75059459, -1258.11357556,\n",
              "        -1252.06375291]),\n",
              " 'param_colsample_bytree': masked_array(data=[0.6000000000000001, 0.6000000000000001,\n",
              "                    0.6000000000000001, 0.6000000000000001,\n",
              "                    0.6000000000000001],\n",
              "              mask=[False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0.30000000000000004, 0.1, 0.30000000000000004, 0.2,\n",
              "                    0.1],\n",
              "              mask=[False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_subsample': masked_array(data=[0.6000000000000001, 0.8, 0.7000000000000001, 0.5, 0.9],\n",
              "              mask=[False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'colsample_bytree': 0.6000000000000001,\n",
              "   'gamma': 0.30000000000000004,\n",
              "   'subsample': 0.6000000000000001},\n",
              "  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.1, 'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6000000000000001,\n",
              "   'gamma': 0.30000000000000004,\n",
              "   'subsample': 0.7000000000000001},\n",
              "  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.2, 'subsample': 0.5},\n",
              "  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.1, 'subsample': 0.9}],\n",
              " 'rank_test_score': array([4, 2, 3, 5, 1], dtype=int32),\n",
              " 'split0_test_score': array([-1262.99585291, -1258.49353377, -1261.73388163, -1268.63183061,\n",
              "        -1257.27335524]),\n",
              " 'split1_test_score': array([-1247.16031471, -1245.94349938, -1244.85635242, -1248.3559184 ,\n",
              "        -1243.89679555]),\n",
              " 'split2_test_score': array([-1257.34076023, -1256.6371765 , -1254.66154972, -1257.35297767,\n",
              "        -1255.02110793]),\n",
              " 'std_fit_time': array([0.77763112, 0.30396339, 0.33881886, 0.19129721, 6.35964286]),\n",
              " 'std_score_time': array([0.05686136, 0.02777913, 0.00865792, 0.00295817, 0.03641989]),\n",
              " 'std_test_score': array([6.55223299, 5.53076402, 6.92026625, 8.29506021, 5.84765189])}"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = abs(XGB_random.cv_results_['mean_test_score'])\n",
        "best_gamma = list(XGB_random.cv_results_['param_gamma'].data)\n",
        "best_subsample = list(XGB_random.cv_results_['param_subsample'].data)"
      ],
      "metadata": {
        "id": "fvN9vCafQ31R"
      },
      "id": "fvN9vCafQ31R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_random.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6u1Nvmjkx1a",
        "outputId": "297f9fa4-4177-4b74-90b7-7fdf244c1aae"
      },
      "id": "p6u1Nvmjkx1a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1252.063752907384"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I65_wOFyQ_UB",
        "outputId": "fb960627-12c8-43d3-db77-365f3222c72b"
      },
      "id": "I65_wOFyQ_UB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.6000000000000001, 'gamma': 0.1, 'subsample': 0.9}"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Model :"
      ],
      "metadata": {
        "id": "JnZd9N3ThC0Q"
      },
      "id": "JnZd9N3ThC0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "bst_model = XGBRegressor(num_boost_round=200, eta=0.07, gamma=0.1, max_depth=8, min_child_weight=6,\n",
        "                                         colsample_bytree=0.6, subsample=0.9)\n",
        "bst_model.fit(train_x, train_y.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6vs-qLhEkU",
        "outputId": "7102aef5-0069-4d64-9e16-7dc698edf8ed"
      },
      "id": "aj6vs-qLhEkU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(colsample_bytree=0.6, eta=0.07, gamma=0.1, max_depth=8,\n",
              "             min_child_weight=6, num_boost_round=200, subsample=0.9)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = bst_model.predict(x_cv_base)\n",
        "print(mean_absolute_error(y_cv, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJjC2VJUn5Lc",
        "outputId": "d26758b8-3533-409d-e626-657584a8c1ae"
      },
      "id": "JJjC2VJUn5Lc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1094.658741213913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion :\n",
        "\n",
        "Here after hyperparameter tuning we get best score of 1094.65. This score can be further improved by using more complex model and using different hyperparameter tuning.\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "### Room for Improvement \n",
        "1.   Fit a more complex XGBoost model by adding even more estimators and reducing eta at the same time.\n",
        "2.   Run Grid Search on different values of hyperparameters.\n",
        "3.   Ensemble several XGBoost models, trained with different hyperparameters. This can be done by bagging (averaging the score of the models), blending and stacking.\n",
        "\n"
      ],
      "metadata": {
        "id": "iJfyhFfFhXnK"
      },
      "id": "iJfyhFfFhXnK"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WXMk0GvnqANn"
      },
      "id": "WXMk0GvnqANn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Hyperparameter Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}